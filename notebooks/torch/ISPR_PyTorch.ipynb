{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hubWOvFpYFpJ"
   },
   "source": [
    "![PyTorch](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/640px-PyTorch_logo_black.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3pNex87YFpL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Using torch v{torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE9EZPFAbzUI"
   },
   "source": [
    "## Tensor Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnwj2LpIYFpL"
   },
   "outputs": [],
   "source": [
    "# Initialize zero dense tensor\n",
    "dims = (4, 5, 3)\n",
    "t = torch.zeros(*dims)\n",
    "print(f\"Shape:   {t.shape}\")\n",
    "print(f\"Type:    {t.dtype}\")\n",
    "print(f\"Layout:  {t.layout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27zTiqgzYFpM"
   },
   "outputs": [],
   "source": [
    "# Initialize zero sparse tensor\n",
    "t = torch.zeros(*dims, layout=torch.sparse_coo)\n",
    "print(f\"Shape:   {t.shape}\")\n",
    "print(f\"Type:    {t.dtype}\")\n",
    "print(f\"Layout:  {t.layout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vq0IF0X8YFpM"
   },
   "outputs": [],
   "source": [
    "# Random tensor\n",
    "t1 = torch.randn(*dims) # Normal Distribution\n",
    "t2 = torch.rand(*dims)  # Uniform Distribution\n",
    "t3 = torch.randint(-10, 10, dims) # Unif Dist. (Categorical)\n",
    "\n",
    "print(f\"dtype t1: {t1.dtype}\")\n",
    "print(f\"dtype t2: {t2.dtype}\")\n",
    "print(f\"dtype t3: {t3.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "At55DuUX4RWx"
   },
   "outputs": [],
   "source": [
    "# Types are casted by operators\n",
    "t4 = t1 + t2 * t3\n",
    "print(f\"dtype t4: {t4.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LPCV9wU5Fxu"
   },
   "outputs": [],
   "source": [
    "# ...or manually casted\n",
    "torch.random.manual_seed(42)\n",
    "dims = (3, 2)\n",
    "t5 = torch.randint(0, 2, dims)\n",
    "t6 = t5.bool()\n",
    "t7 = t5.float()\n",
    "t8 = t5.long()\n",
    "t9 = t5.double()\n",
    "print(f\"t5 ({t5.dtype}) =\\n {t5}\")\n",
    "print(f\"t6 ({t6.dtype}) =\\n {t6}\")\n",
    "print(f\"t7 ({t7.dtype}) =\\n {t7}\")\n",
    "print(f\"t8 ({t8.dtype}) =\\n {t8}\")\n",
    "print(f\"t9 ({t9.dtype}) =\\n {t9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYSuCEfyOd6O"
   },
   "source": [
    "## Tensors in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btRuxv0O4oTN"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available:\n",
    "  device = torch.device(\"cuda\")\n",
    "  devices = list(range(torch.cuda.device_count()))\n",
    "  if len(devices) > 0:\n",
    "    device = torch.device(f\"cuda:{devices[0]}\")\n",
    "    print(f\"Using GPU {device}\")\n",
    "  else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA available, but no GPU available\")\n",
    "else:\n",
    "  print(\"CUDA is not available\")\n",
    "  device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTA6uDsPOsuY"
   },
   "outputs": [],
   "source": [
    "if device != torch.device(\"cpu\"):\n",
    "  t1_gpu = t1.to(device)\n",
    "  t2_gpu = t2.to(\"cuda\")\n",
    "  t3_gpu = t3.to(\"cuda:0\")\n",
    "\n",
    "  print(t1_gpu.device, t2_gpu.device, t3_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTSwc4GnPFF3"
   },
   "outputs": [],
   "source": [
    "if device != torch.device(\"cpu\"):\n",
    "  t4_gpu = t1_gpu + t2_gpu * t3_gpu\n",
    "  print(t4_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0m-uPUlYFpN"
   },
   "outputs": [],
   "source": [
    "if device != torch.device(\"cpu\"):\n",
    "  try:\n",
    "    t4_mixed = t4_gpu + t4\n",
    "  except RuntimeError as e:\n",
    "    t4_mixed = None\n",
    "    print(e)\n",
    "\n",
    "  assert t4_mixed is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYbdCWUEZoCm"
   },
   "source": [
    "## Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqV_HM3JZle7"
   },
   "outputs": [],
   "source": [
    "# Create integer range on tensor a with dim (3, 4, 2)\n",
    "torch.manual_seed(42)\n",
    "arr = torch.arange(24).reshape(3, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQpYtxwYfx8K"
   },
   "outputs": [],
   "source": [
    "# Index the first two entries on the first dimension\n",
    "arr[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7RTF2eAf-wc"
   },
   "outputs": [],
   "source": [
    "# Index the last two entries on the first dimension\n",
    "arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Av8sWpJPgDLA"
   },
   "outputs": [],
   "source": [
    "# Index the last two entries on the first dimension\n",
    "arr[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aug-pAhkgHeQ"
   },
   "outputs": [],
   "source": [
    "# Mixed indexing\n",
    "arr[1:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emz9XiWagQZg"
   },
   "outputs": [],
   "source": [
    "# Mixed indexing\n",
    "arr[-2:, 1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cR0R_GOgTrJ"
   },
   "outputs": [],
   "source": [
    "# Boolean conditions\n",
    "even_entries = arr % 2 == 0\n",
    "print(even_entries)\n",
    "arr[even_entries] = -1\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuUPET3tg1gX"
   },
   "source": [
    "## Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiMKv2ehg00D"
   },
   "outputs": [],
   "source": [
    "t = torch.randn(3, 1, 5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EaPlmtBg9tK"
   },
   "outputs": [],
   "source": [
    "t.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXlmwecnhPjf"
   },
   "outputs": [],
   "source": [
    "t.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZDOXuYVhV_Z"
   },
   "outputs": [],
   "source": [
    "t.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNVD6i0Lg_z6"
   },
   "outputs": [],
   "source": [
    "t.unsqueeze(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGPDCsYthCbd"
   },
   "outputs": [],
   "source": [
    "t.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_o4CTUJhJqG"
   },
   "outputs": [],
   "source": [
    "t.permute(1, 0, 2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4iPTxc-hieg"
   },
   "source": [
    "## Tensor Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLnJcOKhhj-B"
   },
   "outputs": [],
   "source": [
    "t = torch.randn(5, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOGGo5KjiaIw"
   },
   "outputs": [],
   "source": [
    "red_t = t.sum(0)\n",
    "print(f\"Shape: {red_t.shape}\")\n",
    "red_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ9NT4Bti768"
   },
   "outputs": [],
   "source": [
    "red_t = t.sum(0, keepdim=True)\n",
    "print(f\"Shape: {red_t.shape}\")\n",
    "red_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umF2hKF1imCE"
   },
   "outputs": [],
   "source": [
    "red_t = t.mean(0)\n",
    "print(f\"Shape: {red_t.shape}\")\n",
    "red_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVxTU01-iupn"
   },
   "outputs": [],
   "source": [
    "red_t = t.mean((0, 2), keepdim=True)\n",
    "print(f\"Shape: {red_t.shape}\")\n",
    "red_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT14YiC8kc4n"
   },
   "source": [
    "## Tensor Initialization: Your Turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ym5bMWSlkl1n"
   },
   "outputs": [],
   "source": [
    "def relu_kaiming_init(in_size: int, out_size: int) -> torch.Tensor:\n",
    "  pass\n",
    "\n",
    "def relu_kaiming_init_(weights: torch.Tensor):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fNy-C_qwbM8"
   },
   "outputs": [],
   "source": [
    "# Test test test!\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Right shape\n",
    "t1 = relu_kaiming_init(5, 10)\n",
    "assert t1.shape == (10, 5)\n",
    "\n",
    "# Inplace edit\n",
    "t2 = torch.zeros(30, 25)\n",
    "t2_old = t2.clone()\n",
    "relu_kaiming_init_(t2)\n",
    "assert not torch.allclose(t2_old, t2)\n",
    "assert torch.allclose(t2_old, torch.tensor(0.0))\n",
    "\n",
    "# Mean\n",
    "print(f\"Mean: {t2.mean()}\")\n",
    "print(f\"Std: {t2.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF_ST8pbkIbQ"
   },
   "source": [
    "## AutoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Q8ngRvwkOHL"
   },
   "outputs": [],
   "source": [
    "t = torch.randn(2, 4, 5)\n",
    "t.data, t.grad, t.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEdP04w8k7d5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "batch_size = 32\n",
    "in_shape = 5\n",
    "hh_shape = 10\n",
    "\n",
    "# Input (Current Step)\n",
    "x = torch.randn(batch_size, in_shape)\n",
    "# Hidden Representation (Previous Step)\n",
    "prev_h = torch.randn(batch_size, hh_shape)\n",
    "\n",
    "# Computation\n",
    "W_x = torch.randn(hh_shape, in_shape, requires_grad=True)\n",
    "i2h = torch.mm(x, W_x.t())\n",
    "W_h = torch.randn(hh_shape, hh_shape, requires_grad=True)\n",
    "h2h = torch.mm(prev_h, W_h.t())\n",
    "next_h = i2h + h2h\n",
    "next_h = next_h.tanh()\n",
    "\n",
    "print(next_h.shape)\n",
    "\n",
    "# Let AutoGrad compute the derivative of tensors requiring grad\n",
    "print(next_h.backward(torch.ones(batch_size, hh_shape)))\n",
    "\n",
    "print(f\"x.grad: {x.grad}\")\n",
    "print(f\"prev_h.grad: {prev_h.grad}\")\n",
    "print(f\"W_h.grad ({W_h.grad.shape})\\n{W_h.grad}\")\n",
    "print(f\"W_x.grad ({W_x.grad.shape})\\n{W_x.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFyEPBVRmgBr"
   },
   "source": [
    "## Torch Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHqa8c3foaTz"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ISPR_LinearLayer(nn.Module):\n",
    "  def __init__(self, in_shape, out_shape, kaiming_custom = False):\n",
    "    super().__init__()\n",
    "    self.weight = nn.Parameter(torch.randn(out_shape, in_shape))\n",
    "    self.bias = nn.Parameter(torch.randn(out_shape))\n",
    "\n",
    "    if kaiming_custom:\n",
    "      # Why would this lead to an error without torch.no_grad()?\n",
    "      with torch.no_grad():\n",
    "        relu_kaiming_init_(self.weight)\n",
    "    else:\n",
    "      # Default PyTorch Version\n",
    "      nn.init.kaiming_uniform_(self.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "\n",
    "    nn.init.zeros_(self.bias)\n",
    "\n",
    "  def forward(self, in_tensor):\n",
    "    return in_tensor @ self.weight.t() + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR5e8Qt9mfLB"
   },
   "outputs": [],
   "source": [
    "class ISPR_MultilayerPerceptron(nn.Module):\n",
    "  def __init__(self,\n",
    "               layer_size: list[int],\n",
    "               wrong_list: bool = False):\n",
    "    \"\"\"\n",
    "    Multi-layer Perceptron, where the size\n",
    "    of each layer is contained in the `layer_size` list.\n",
    "    \"\"\"\n",
    "    super().__init__() #<- remember to call the superclass\n",
    "\n",
    "    fully_connected = [\n",
    "        ISPR_LinearLayer(layer_size[i], layer_size[i+1])\n",
    "        for i in range(len(layer_size) - 1)]\n",
    "\n",
    "    # Wrong list\n",
    "    if wrong_list:\n",
    "      self.fc = fully_connected\n",
    "    else:\n",
    "      self.fc = nn.ModuleList(fully_connected)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    for fc_layer in self.fc:\n",
    "      x = fc_layer(x)\n",
    "      x = F.relu(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "layers = [5, 10, 20, 1]\n",
    "net_1 = ISPR_MultilayerPerceptron(layers)\n",
    "net_2 = ISPR_MultilayerPerceptron(layers, wrong_list=True)\n",
    "\n",
    "print(f\"Net1 parameters: {len(list(net_1.parameters()))}\")\n",
    "print(f\"Net2 parameters: {len(list(net_2.parameters()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmqE5xAJrD3Q"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcWto9WqrC-8"
   },
   "outputs": [],
   "source": [
    "# Set seed to generate simulated dataset\n",
    "torch.manual_seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "x_data = torch.randn(n_samples, 5)\n",
    "y_data = net_1(x_data) + 1e-2 * torch.randn(n_samples, 1)\n",
    "\n",
    "# Important! Detach y_data\n",
    "y_data = y_data.detach()\n",
    "\n",
    "print(f\"x_data shape: {x_data.shape}\")\n",
    "print(f\"y_data shape: {y_data.shape}\")\n",
    "\n",
    "# Create dataset\n",
    "dset = torch.utils.data.TensorDataset(x_data, y_data)\n",
    "\n",
    "# Split train, val, test (0.7, 0.2, 0.1)\n",
    "n_train = int(0.7 * n_samples)\n",
    "n_val = int(0.2 * n_samples)\n",
    "n_test = n_samples - n_train - n_val\n",
    "\n",
    "# Split dataset\n",
    "train_dset, val_dset, test_dset = \\\n",
    "  torch.utils.data.random_split(dset, [n_train, n_val, n_test])\n",
    "\n",
    "# Create loaders\n",
    "batch_size = 32\n",
    "tr_loader = torch.utils.data.DataLoader(train_dset, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dset, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size)\n",
    "\n",
    "# Print lengths\n",
    "print(f\"Train loader length: {len(tr_loader)}\")\n",
    "print(f\"Val loader length: {len(val_loader)}\")\n",
    "print(f\"Test loader length: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDYzqbh8ogBi"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTFtLsbooU27"
   },
   "outputs": [],
   "source": [
    "# Init Module\n",
    "net_hat = ISPR_MultilayerPerceptron([5, 5, 5, 1])\n",
    "\n",
    "# Mean Squared Error\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD(net_hat.parameters(), lr=1e-2)\n",
    "\n",
    "# Training Loop\n",
    "n_epochs = 500\n",
    "\n",
    "tr_loss = []\n",
    "vl_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  # Train\n",
    "  net_hat.train()\n",
    "  epoch_tr_loss = []\n",
    "  for x, y in tr_loader:\n",
    "    y_hat = net_hat(x)\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    epoch_tr_loss.append(loss.item())\n",
    "  epoch_tr_loss = torch.tensor(epoch_tr_loss)\n",
    "  epoch_tr_loss = torch.mean(epoch_tr_loss)\n",
    "\n",
    "  # Validation\n",
    "  net_hat.eval()\n",
    "  epoch_val_loss = []\n",
    "  with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "      y_hat = net_hat(x)\n",
    "      loss = loss_fn(y_hat, y)\n",
    "      epoch_val_loss.append(loss.item())\n",
    "  epoch_val_loss = torch.tensor(epoch_val_loss)\n",
    "  epoch_val_loss = torch.mean(epoch_val_loss)\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Epoch. {epoch} | Train Loss: {epoch_tr_loss} | Val Loss: {epoch_val_loss}\")\n",
    "\n",
    "  tr_loss.append(epoch_tr_loss.item())\n",
    "  vl_loss.append(epoch_val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWRNRaLMNCfG"
   },
   "outputs": [],
   "source": [
    "# Test Set Performance\n",
    "net_hat.eval()\n",
    "test_loss = []\n",
    "with torch.no_grad():\n",
    "  for x, y in test_loader:\n",
    "    y_hat = net_hat(x)\n",
    "    loss = loss_fn(y_hat, y)\n",
    "    test_loss.append(loss.item())\n",
    "test_loss = torch.tensor(test_loss)\n",
    "test_loss = torch.mean(test_loss).item()\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch2xolduoezt"
   },
   "outputs": [],
   "source": [
    "# Seaborn plot training loss and validation loss\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "sns.lineplot(x=range(n_epochs), y=tr_loss, label=\"Train Loss\")\n",
    "sns.lineplot(x=range(n_epochs), y=vl_loss, label=\"Val Loss\")\n",
    "# Plot horizontal line for test loss\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3d-OI2nOV33"
   },
   "source": [
    "## Your Turn!\n",
    "\n",
    "1. Download the MNIST dataset using [torchvision](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html).\n",
    "2. Instantiate a Convolutional Neural Network (CNN)\n",
    "3. Train the CNN to classify the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9k_EnI5looc2"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load Dataset\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    'data/', train=True, download=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    'data/', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# TODO: Use GPU?\n",
    "\n",
    "# TODO: Split MNIST Train and Validation\n",
    "\n",
    "# TODO: Create data loaders\n",
    "\n",
    "# TODO: Define class CNN\n",
    "\n",
    "# TODO: Instantiate CNN\n",
    "\n",
    "# TODO: Train the CNN\n",
    "\n",
    "# TODO: Test Set Performance\n",
    "\n",
    "# TODO: Plot Training Loss and Validation Loss (W&B, TensorBoard, or plain Matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
